---
title: "Practice Assignment 2 MATH 343"
author: "Carlos Vega"
output: pdf_document
date: "11:59PM April 11"
---

This practice assignment is coupled to the theory assignment (the problem numbers align herein) and should be worked on concomitantly. You will write code in places marked "TO-DO" to complete the problems. Most of this will be a pure programming assignment but there are some questions that instead ask you to "write a few sentences" which are not R chunks.

The tools for solving these problems can be found in the class demos located [here](https://github.com/kapelner/QC_MATH_343_Spring_2024/tree/main/demos).

To "hand in" the homework, push this completed file by the due date to your course repo.

NOT REQUIRED: After you're done, you have the option to compile this file into a PDF (use the "knit to PDF" button on the submenu above). These final PDF's look pretty as it includes the output of your code. You can push the PDF as well. It will look nice in your portfolio.

This lab requires the following packages. You should make sure they load before beginning:

```{r}
pacman::p_load(ggplot2, glmnet, survival, lmtest, skimr, MASS, mlbench, rstan)
```

## Problem 1: Inference for the linear model using the OLS estimator

Below is a design matrix taken from the boston housing data and a definition of some variables.

```{r}
X = model.matrix(medv ~ ., MASS::Boston)
n = nrow(X)
p_plus_one = ncol(X)
XtXinvXt = solve(t(X) %*% X) %*% t(X)
H = X %*% XtXinvXt
In_minus_H = diag(n) - H
```

We will now assume betas of all ones and a sigma of 2:

```{r}
betavec = rep(1, p_plus_one)
sigsq = 2^2
```

We will now simulate many response vectors sing the core assumption. Remember that the `rnorm` function takes sigma (not sigma-squared) as an argument. Then we'll use the response vectors to compute b, yhat and e. We will collect them all into matrices so we can investigate their behavior later.

```{r}
Nsim = 10000
bs = matrix(NA, nrow = p_plus_one, ncol = Nsim)
yhats = matrix(NA, nrow = n, ncol = Nsim)
es = matrix(NA, nrow = n, ncol = Nsim)
set.seed(1)
for (nsim in 1 : Nsim){
  epsilon = rnorm(n, mean = 0, sd = sqrt(sigsq))
  y = X %*% betavec + epsilon
  b = XtXinvXt %*% y
  yhat = X %*% b
  e = y - yhat
  bs[, nsim] = b
  yhats[, nsim] = yhat
  es[, nsim] = e
}
```

Let's now make sure the formulas are correct for Yhat. Let's take the 17th observation and standardize its values based on knowledge of the true betas and the formulas from class. We can plot them here:

```{r}
yhat17s_std = (yhats[17,] - X[17,] %*% betavec) / (sqrt(sigsq) * sqrt(H[17,17]))
ggplot(data.frame(yhat17s_std = yhat17s_std)) + aes(x = yhat17s_std) + geom_histogram()
```

This distribution should look like a standard normal. Confirm that you cannot reject a Kolmogorov-Smirnov test that `yhat17s_std` comes from an iid N(0, 1) DGP:

```{r}
ks.test(yhat17s_std, "pnorm", mean = 0, sd = 1)
```

Repeat this Kolmogorov-Smirnov test for the 7th entry of b.

```{r}
b7s_std = (bs[7,] - betavec[7]) / (sqrt(sigsq) * sqrt(solve(t(X) %*% X)[7,7]))
ks.test(b7s_std, "pnorm", mean = 0, sd = 1)
```

Repeat this Kolmogorov-Smirnov test for the 37th entry of e.

```{r}
e37s_std = es[37,] / (sqrt(sigsq) * sqrt(1 - H[37,37]))
ks.test(e37s_std, "pnorm", mean = 0, sd = 1)
```

Now let's work with just one realization of the errors which gives us one estimate of y, b, yhat and e:

```{r}
b = bs[, 1]
yhat = yhats[, 1]
e = es[, 1]
y = yhat + e
```

At level alpha = 5%, test H_0: beta_7 = 0 by calculating the t-statistic and comparing it to the appropriate critical value of t.

```{r}
s_squared = sum(e^2) / (n - (p_plus_one))
s_e = sqrt(s_squared)

se_b7 = s_e * sqrt(solve(t(X) %*% X)[7,7])

t_stat = (b[7] - 0) / se_b7

alpha = 0.05
critical_value = qt(1 - alpha/2, df = n - p_plus_one)

reject_h0 = abs(t_stat) > critical_value

cat("t-statistic:", t_stat, "\n")
cat("Critical value:", critical_value, "\n")
cat("Reject H0:", reject_h0, "\n")
```

Create a 95% CI for mu_17, the expected value of the 17th observation in the X matrix.

```{r}
mu_17_true = X[17,] %*% betavec
mu_17_estimated = X[17,] %*% b

se_mu_17 = s_e * sqrt(X[17,] %*% solve(t(X) %*% X) %*% X[17,])

critical_value = qt(0.975, df = n - p_plus_one)

lower_bound = mu_17_estimated - critical_value * se_mu_17
upper_bound = mu_17_estimated + critical_value * se_mu_17

cat("95% CI for mu_17: [", lower_bound, ", ", upper_bound, "]\n")
cat("True mu_17:", mu_17_true, "\n")
```

Create a 95% CI for y_17, the response value for the 17th observation in the X matrix.

```{r}
se_pred_17 = s_e * sqrt(1 + X[17,] %*% solve(t(X) %*% X) %*% X[17,])

lower_bound_y = mu_17_estimated - critical_value * se_pred_17
upper_bound_y = mu_17_estimated + critical_value * se_pred_17

cat("95% CI for y_17: [", lower_bound_y, ", ", upper_bound_y, "]\n")
cat("Actual y_17:", y[17], "\n")
```

Run the omnibus test at level alpha = 5% by calculating the quantities from scratch and comparing to the appropriate critical F value.
 
```{r}
y_bar = mean(y)
SSR = sum((yhat - y_bar)^2)

# Calculate SSE (sum of squares error)
SSE = sum(e^2)

# Calculate MSR (mean square regression) and MSE (mean square error)
p = p_plus_one - 1  # number of predictors (excluding intercept)
MSR = SSR / p
MSE = SSE / (n - p_plus_one)

# Calculate F-statistic
F_stat = MSR / MSE

# Find critical F-value
critical_F = qf(1 - alpha, df1 = p, df2 = n - p_plus_one)

# Decision rule
reject_h0_omnibus = F_stat > critical_F

# Print results
cat("F-statistic:", F_stat, "\n")
cat("Critical F-value:", critical_F, "\n")
cat("Reject H0 (all beta_j = 0 for j > 0):", reject_h0_omnibus, "\n")
```

Run the multiple effect test for H_0: beta_1 = beta_2 = beta_3 = 0 at level alpha = 5% by calculating the quantities from scratch and comparing to the appropriate critical F value.

```{r}
X_reduced = X[, -c(2, 3, 4)]
b_reduced = solve(t(X_reduced) %*% X_reduced) %*% t(X_reduced) %*% y
yhat_reduced = X_reduced %*% b_reduced
e_reduced = y - yhat_reduced
SSE_reduced = sum(e_reduced^2)

k = 3 
F_stat_mult = ((SSE_reduced - SSE) / k) / (SSE / (n - p_plus_one))
critical_F_mult = qf(1 - alpha, df1 = k, df2 = n - p_plus_one)

reject_h0_mult = F_stat_mult > critical_F_mult

cat("F-statistic (multiple effect):", F_stat_mult, "\n")
cat("Critical F-value:", critical_F_mult, "\n")
cat("Reject H0 (beta_1 = beta_2 = beta_3 = 0):", reject_h0_mult, "\n")
```

Compute the maximum likelihood estimator for sigsq.

```{r}
sigsq_mle = SSE / n
cat("MLE for sigma^2:", sigsq_mle, "\n")
cat("Unbiased estimator for sigma^2:", SSE / (n - p_plus_one), "\n")
cat("True sigma^2:", sigsq, "\n")
```

## Problem 2: Ridge and Lasso predictions

We'll use the data setup from class: the boston housing data with another 1000 garbage features tacked on and then all features standardized:

```{r}
rm(list = ls())
p_extra = 1000

set.seed(1)
y = MASS::Boston$medv
X = model.matrix(medv ~ ., MASS::Boston)
X = cbind(X, matrix(rnorm(nrow(X) * p_extra), ncol = p_extra))
colnames(X) = c("(Intercept)", colnames(MASS::Boston)[1:13], paste0("junk_", 1 : p_extra))

X = apply(X, 2, function(x_dot_j){(x_dot_j - mean(x_dot_j)) / sd(x_dot_j)})
X[, 1] = 1 #reset the intercept
```

We will now split the data into training (with 400 observations) and test:

```{r}
train_idx = sample(1 : nrow(X), 400)
test_idx = setdiff(1 : nrow(X), train_idx)
Xtrain = X[train_idx, ]
ytrain = y[train_idx]
Xtest =  X[test_idx, ]
ytest =  y[test_idx]
```

In class we fit many ridge models and many lasso models using arbitrary values of lambda. Here we will use the model selection technique from 342W implementing inner K-fold CV but not the outer K-fold CV. We can use the `cv.glmnet` function to do this. You can use its default lambda grid search. Run both ridge and lasso. Report the optimal lambda values for ridge and lasso.

```{r}
set.seed(123)
ridge_cv = cv.glmnet(Xtrain, ytrain, alpha = 0, nfolds = 10)
lambda_opt_ridge = ridge_cv$lambda.min

set.seed(123)
lasso_cv = cv.glmnet(Xtrain, ytrain, alpha = 1, nfolds = 10)
lambda_opt_lasso = lasso_cv$lambda.min

cat("Optimal lambda for Ridge:", lambda_opt_ridge, "\n")
cat("Optimal lambda for Lasso:", lambda_opt_lasso, "\n")

par(mfrow = c(1, 2))
plot(ridge_cv, main = "Ridge CV")
plot(lasso_cv, main = "Lasso CV")
```

Now fit both the ridge and lasso models using their respective optimal values of lambda.

```{r}
ridge_mod = glmnet(Xtrain, ytrain, alpha = 0, lambda = lambda_opt_ridge)
lasso_mod = glmnet(Xtrain, ytrain, alpha = 1, lambda = lambda_opt_lasso)
```

For the lasso model, which features did it select?

```{r}
lasso_coefs = coef(lasso_mod)
nonzero_lasso = which(lasso_coefs != 0)
selected_features = rownames(lasso_coefs)[nonzero_lasso]

cat("Number of features selected by lasso:", length(selected_features) - 1, "\n")
cat("Selected features (first 20):\n")
print(head(selected_features, 20))
```

Now predict on the test set and calculate oosRMSE. Who wins?

```{r}
ridge_pred = predict(ridge_mod, newx = Xtest)
ridge_rmse = sqrt(mean((ridge_pred - ytest)^2))

lasso_pred = predict(lasso_mod, newx = Xtest)
lasso_rmse = sqrt(mean((lasso_pred - ytest)^2))

cat("Ridge RMSE on test set:", ridge_rmse, "\n")
cat("Lasso RMSE on test set:", lasso_rmse, "\n")
cat("Winner:", ifelse(ridge_rmse < lasso_rmse, "Ridge", "Lasso"), "\n")
```


# Problem 3: Robust regression methods

Let's use 1000 rows of the diamonds dataset for this exercise. We'll convert the ordinal factors to nominal to make the feature dummy names more readable.

```{r}
rm(list = ls())
diamonds = ggplot2::diamonds
?diamonds
diamonds$cut =      factor(diamonds$cut, ordered = FALSE)      #convert to nominal
diamonds$color =    factor(diamonds$color, ordered = FALSE)    #convert to nominal
diamonds$clarity =  factor(diamonds$clarity, ordered = FALSE)  #convert to nominal

set.seed(1)
idx = sample(1 : nrow(diamonds), 1000)
X = model.matrix(price ~ ., diamonds[idx, ])
y = diamonds$price[idx]
rm(list = setdiff(ls(), c("X", "y")))
```

Fit a linear model on all features and report the p-value for the test of H_0: beta_j = 0 where j is the index of the `depth` feature.

```{r}
lm_model = lm(y ~ X - 1)

depth_col = grep("depth", colnames(X))
cat("Column for depth feature:", depth_col, "\n")

depth_pvalue = summary(lm_model)$coefficients[depth_col, 4]
cat("P-value for H0: beta_depth = 0:", depth_pvalue, "\n")
```

Now assume nothing is known about the error DGP except that they are independent.

Report an asymptotically valid p-value for the test of H_0: beta_j = 0 where j is the index of the `depth` feature.

```{r}
pacman::p_load(sandwich)
library(sandwich)
library(lmtest)

robust_se = sqrt(diag(vcovHC(lm_model, type = "HC0")))

beta_depth = coef(lm_model)[depth_col]
t_stat_robust = beta_depth / robust_se[depth_col]

p_value_robust = 2 * pnorm(-abs(t_stat_robust))
cat("Asymptotically valid p-value for H0: beta_depth = 0:", p_value_robust, "\n")
```

Now assume the errors are mean-centered and homoskedastic. 

Report an asymptotically valid p-value for the test of H_0: beta_j = 0 where j is the index of the `depth` feature.

```{r}
homoskedastic_pvalue = summary(lm_model)$coefficients[depth_col, 4]
cat("Asymptotically valid p-value under homoskedasticity:", homoskedastic_pvalue, "\n")
```

Report an asymptotically valid p-value for the test of H_0: beta_j = 0 and beta_k = 0 where j is the index of the `depth` feature and k is the index of the `table` feature.

```{r}
table_col = grep("table", colnames(X))
cat("Column for table feature:", table_col, "\n")

ind_restricted = c(depth_col, table_col)
X_restricted = X[, -ind_restricted]
lm_restricted = lm(y ~ X_restricted - 1)

anova_result = anova(lm_restricted, lm_model)
F_stat = anova_result$F[2]
p_value = anova_result$`Pr(>F)`[2]

cat("F-statistic for H0: beta_depth = beta_table = 0:", F_stat, "\n")
cat("Asymptotically valid p-value:", p_value, "\n")
```

Now assume the errors are mean-centered and heteroskedastic. This is the scenario where you employ the Huber-White estimator.

Report an asymptotically valid p-value for the test of H_0: beta_j = 0 where j is the index of the `depth` feature.

```{r}
# Get the actual variable name at the depth column position
depth_var_name = names(coef(lm_model))[depth_col]

# First create a restricted model manually by removing that specific variable
restricted_formula <- as.formula(paste0(". ~ . - ", depth_var_name))
lm_model_restricted <- update(lm_model, restricted_formula)

# Then perform the test comparing the two models
depth_test = waldtest(lm_model_restricted, lm_model, vcov = function(x) vcovHC(x, type = "HC0"))
cat("Huber-White p-value for H0: beta_depth = 0:", depth_test$"Pr(>F)"[2], "\n")
```

Report an asymptotically valid p-value for the test of H_0: beta_j = 0 and beta_k = 0 where j is the index of the `depth` feature and k is the index of the `table` feature.

```{r}
joint_test = waldtest(lm_model, 
                      terms = paste0("X", c(depth_col, table_col)), 
                      vcov = vcovHC(lm_model, type = "HC0"))
cat("Huber-White p-value for H0: beta_depth = beta_table = 0:", joint_test$"Pr(>F)"[2], "\n")
```

# Problem 4a: Inference for Bernoulli Response Models

We load up the Glass dataset below. The goal is to predict and understand the effects of features on whether or not the glass is of type 1.

```{r}
rm(list = ls())
data(Glass)
glass = na.omit(Glass)
glass$Type = ifelse(glass$Type == 1, 1, 0)
```

Fit a probit regression using all features and report p-values for H_0: beta_j = 0 for all features. Using the `glm` function with `family = binomial(link = "probit")`.

```{r}
probit_model = glm(Type ~ ., data = glass, family = binomial(link = "probit"))

summary(probit_model)
```

Run the omnibus test at level alpha=5% to see if any of these features are useful in predicting the probability of Type=1.

```{r}
null_model = glm(Type ~ 1, data = glass, family = binomial(link = "probit"))

lr_test = anova(null_model, probit_model, test = "Chisq")
print(lr_test)

p_value_omnibus = lr_test$`Pr(>Chi)`[2]
alpha = 0.05
reject_h0 = p_value_omnibus < alpha
cat("Omnibus test p-value:", p_value_omnibus, "\n")
cat("Reject H0 (all coefficients = 0):", reject_h0, "\n")
```


Predict the probability of glass being of type 1 if the sample had average amounts of all features.

```{r}
x_vec_avg = data.frame(t(apply(glass, 2, mean)))
x_vec_avg$Type = NULL  # Remove Type column from predictors

pred_prob = predict(probit_model, newdata = x_vec_avg, type = "response")
cat("Predicted probability of Type=1 for average glass:", pred_prob, "\n")
```

Add quadratic terms to all the features and fit a new model. Check if these additional features are justified at level alpha=5%.

```{r}
glass_quad = glass
for (col in names(glass)[names(glass) != "Type"]) {
  new_col_name = paste0(col, "_sq")
  glass_quad[[new_col_name]] = glass[[col]]^2
}

probit_model_quad = glm(Type ~ ., data = glass_quad, family = binomial(link = "probit"))

lr_test_quad = anova(probit_model, probit_model_quad, test = "Chisq")
print(lr_test_quad)

p_value_quad = lr_test_quad$`Pr(>Chi)`[2]
reject_h0_quad = p_value_quad < alpha
cat("LR test p-value for quadratic terms:", p_value_quad, "\n")
cat("Reject H0 (all quadratic terms = 0):", reject_h0_quad, "\n")
```

# Problem 4b: Inference for Poisson Count Response Model

We load up the insurance dataset below. The goal is to predict and understand the effects of features on number of car insurance claims (the `Claims` column).

```{r}
rm(list = ls())
insur = MASS::Insurance
insur$Group = factor(insur$Group, ordered = FALSE)
insur$Age = factor(insur$Age, ordered = FALSE)
```

Fit a poisson count model (AKA "Poisson regression") to the data and report p-values for H_0: beta_j = 0 for all features. Using the `glm` function with `family="poisson"` defaults to the log link.

```{r}
poisson_model = glm(Claims ~ District + Group + Age, data = insur, family = "poisson")
summary(poisson_model)
```

Predict the number of claims (to the nearest claim) for a someone who lives in a major city, who's age 26, has a 1.8L engine car and has only one policy.

```{r}
new_data = data.frame(
  District = "1",  
  Group = "1",     
  Age = "3"       
)

predicted_claims = predict(poisson_model, newdata = new_data, type = "response")
rounded_claims = round(predicted_claims)

cat("Predicted number of claims:", predicted_claims, "\n")
cat("Rounded to nearest claim:", rounded_claims, "\n")
```

Now fit a Poisson count model that includes the interaction of Age and Holders. Test whether the addition of these interactions is warranted at level alpha=5%.

```{r}
poisson_model_int = glm(Claims ~ District + Group + Age + Group:Age, 
                         data = insur, family = "poisson")

lr_test_int = anova(poisson_model, poisson_model_int, test = "Chisq")
print(lr_test_int)

p_value_int = lr_test_int$`Pr(>Chi)`[2]
reject_h0_int = p_value_int < alpha
cat("LR test p-value for interactions:", p_value_int, "\n")
cat("Reject H0 (all interaction terms = 0):", reject_h0_int, "\n")
```

# Problem 4c: Inference for Negative Binomial Count Response Model

Fit a Negative Binomial count model (AKA "negative binomial regression") to the data and report p-values for H_0: beta_j = 0 for all features. To do this use the `glm.nb` which defaults to the log link.

```{r}
nb_model = MASS::glm.nb(Claims ~ District + Group + Age, data = insur)

summary(nb_model)
```

Predict the number of claims (to the nearest claim) for a someone who lives in a major city, who's age 26, has a 1.8L engine car and has only one policy.

```{r}
predicted_claims_nb = predict(nb_model, newdata = new_data, type = "response")
rounded_claims_nb = round(predicted_claims_nb)

cat("Predicted number of claims (NB):", predicted_claims_nb, "\n")
cat("Rounded to nearest claim (NB):", rounded_claims_nb, "\n")
```

Now fit a Negative Binomial count model that includes the interaction of Age and Holders. Test whether the addition of these interactions is warranted at level alpha=5%.

```{r}
nb_model_int = MASS::glm.nb(Claims ~ District + Group + Age + Group:Age, data = insur)

lr_test_nb_int = anova(nb_model, nb_model_int, test = "Chisq")
print(lr_test_nb_int)

p_value_nb_int = lr_test_nb_int$`Pr(>Chi)`[2]
reject_h0_nb_int = p_value_nb_int < alpha
cat("LR test p-value for interactions (NB):", p_value_nb_int, "\n")
cat("Reject H0 (all interaction terms = 0):", reject_h0_nb_int, "\n")
```


Were there any substantive differences between the inference of prediction you found between the Poisson and Negative Binomial models?

The main difference between the Poisson and Negative Binomial models is that the Negative Binomial model accounts for overdispersion, which is common in count data where variance exceeds the mean. In our results, we can see differences in the estimated coefficients, standard errors, and p-values between the two models. The Negative Binomial model typically provides larger standard errors and thus more conservative inferences. For prediction, the Negative Binomial model can give different estimates, especially for cases where overdispersion is significant. The estimated theta parameter in the Negative Binomial model quantifies this overdispersion.


# Problem 4d: Inference for the Weibull Survival Model

Let's load up data from a trial of usrodeoxycholic acid.

```{r}
rm(list = ls())
udca2 = na.omit(survival::udca2)
?udca2
survival_time = udca2$futime
uncensored_dummy = udca2$status
udca2$id = NULL
udca2$status = NULL
udca2$futime = NULL
udca2$endpoint = NULL
```

We now create a surv object and print out the first 20 entries.

```{r}
surv_obj = Surv(survival_time, uncensored_dummy)
rm(survival_time, uncensored_dummy)
head(surv_obj, 20)
```

What do the "+" signs mean in the above print out?

The "+" signs in the Surv object output indicate right-censored observations. This means that for these patients, the event of interest (e.g., death or disease progression) had not occurred by the end of the observation period. We only know that their survival time is at least as long as the recorded time, but the actual event time is unknown (censored). Right-censoring is common in survival analysis and requires special statistical methods that can account for this partial information.

Fit a Weibull regression model to all features and report p-values for H_0: beta_j = 0 for all features.

```{r}
weibull_model = survreg(surv_obj ~ ., data = udca2, dist = "weibull")
summary(weibull_model)
```

Predict the survival time for a subject with the UDCA treatment (i.e. trt = 1), stage = 1, bili = 1.5 and riskscore = 4.0.

```{r}
new_subject = data.frame(
  trt = 1,
  stage = 1,
  bili = 1.5,
  riskscore = 4.0
)

predicted_log_time = predict(weibull_model, newdata = new_subject)
predicted_time = exp(predicted_log_time)

cat("Predicted survival time:", predicted_time, "days\n")
```

Run the omnibus test at alpha=5%.

```{r}
null_model = survreg(surv_obj ~ 1, dist = "weibull")

lr_test = anova(null_model, weibull_model)
print(lr_test)

p_value_omnibus = lr_test$"Pr(>Chi)"[2]
alpha = 0.05
reject_h0 = p_value_omnibus < alpha
cat("Omnibus test p-value:", p_value_omnibus, "\n")
cat("Reject H0 (all coefficients = 0):", reject_h0, "\n")
```

Run the test to see if the variables stage, bili and riskscore are important in predicting survival at alpha=5%.

```{r}
reduced_model = survreg(surv_obj ~ trt, data = udca2, dist = "weibull")

lr_test_reduced = anova(reduced_model, weibull_model)
print(lr_test_reduced)

p_value_reduced = lr_test_reduced$"Pr(>Chi)"[2]
reject_h0_reduced = p_value_reduced < alpha
cat("LR test p-value for stage, bili, riskscore:", p_value_reduced, "\n")
cat("Reject H0 (all three coefficients = 0):", reject_h0_reduced, "\n")
```